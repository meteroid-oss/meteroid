x-default-logging: &logging
  driver: "json-file"
  options:
    max-size: "5m"
    max-file: "2"
    tag: "{{.Name}}"


networks:
  meteroid_net:

name: meteroid-telemetry

services:

  # ********************
  # Telemetry Components
  #   inspired by https://github.com/open-telemetry/opentelemetry-demo
  #   for development purposes only
  # ********************

  # Jaeger
  #   https://www.jaegertracing.io/docs/1.65/getting-started/#all-in-one
  jaeger:
    image: jaegertracing/jaeger:2.9.0
    container_name: jaeger
    command: [ "--config=/etc/jaeger/config.yaml" ]
    networks:
      - meteroid_net
    ports:
      # expose only what you need; 4317 is inside-network by default
      - "16686:16686"      # Jaeger UI / query HTTP
      # - "4317:4317"      # uncomment if you need OTLP gRPC from host
    volumes:
      - ./volume/jaeger/config.yaml:/etc/jaeger/config.yaml:ro
    deploy:
      resources:
        limits:
          memory: 300M
    restart: unless-stopped
    logging: *logging

  # Grafana
  grafana:
    image: grafana/grafana:12.0
    container_name: grafana
    networks:
      - meteroid_net
    ports:
      - "3000:3000"
    environment:
      - GF_SERVER_ROOT_URL=http://grafana:3000
      - "GF_INSTALL_PLUGINS=grafana-opensearch-datasource"
    volumes:
      - ./volume/grafana/grafana.ini:/etc/grafana/grafana.ini
      - ./volume/grafana/provisioning/:/etc/grafana/provisioning/
    deploy:
      resources:
        limits:
          memory: 120M
    logging: *logging

  # OpenTelemetry Collector
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.133.0
    container_name: otel-collector
    command: [ "--config=/etc/otelcol-config.yml", "--config=/etc/otelcol-config-extras.yml" ]
    user: 0:0
    volumes:
      - /:/hostfs:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./volume/otelcollector/otelcol-config.yml:/etc/otelcol-config.yml
      - ./volume/otelcollector/otelcol-config-extras.yml:/etc/otelcol-config-extras.yml
    networks:
      - meteroid_net
    ports:
      # same as jaeger ports
      - "4317:4317"                        # OTLP over gRPC receiver
      - "4318:4318"                        # OTLP over HTTP receiver
    depends_on:
      jaeger:
        condition: service_started
      opensearch:
        condition: service_healthy
      loki:
        condition: service_started
    deploy:
      resources:
        limits:
          memory: 125M
    restart: unless-stopped
    logging: *logging

  loki:
    image: grafana/loki:3.4.5
    container_name: loki
    command: -config.file=/etc/loki/local-config.yaml
    volumes:
      - ./volume/loki/local-config.yaml:/etc/loki/local-config.yaml
    networks:
      - meteroid_net
    ports:
      - "3100:3100"
    deploy:
      resources:
        limits:
          memory: 100M
    logging: *logging

  # Prometheus
  prometheus:
    image: quay.io/prometheus/prometheus:v3.5.0
    container_name: prometheus
    command:
      - --web.console.templates=/etc/prometheus/consoles
      - --web.console.libraries=/etc/prometheus/console_libraries
      - --storage.tsdb.retention.time=1h
      - --config.file=/etc/prometheus/prometheus-config.yaml
      - --storage.tsdb.path=/prometheus
      - --web.enable-lifecycle
      - --web.route-prefix=/
      - --web.enable-otlp-receiver
      - --enable-feature=exemplar-storage
    volumes:
      - ./volume/prometheus/prometheus-config.yaml:/etc/prometheus/prometheus-config.yaml
    networks:
      - meteroid_net
    ports:
      - "9090:9090"
    deploy:
      resources:
        limits:
          memory: 300M
    logging: *logging

  opensearch:
    image: opensearchproject/opensearch:3.2.0
    container_name: opensearch
    environment:
      - cluster.name=demo-cluster
      - node.name=demo-node
      - bootstrap.memory_lock=true
      - discovery.type=single-node
      - OPENSEARCH_JAVA_OPTS=-Xms300m -Xmx300m
      - DISABLE_INSTALL_DEMO_CONFIG=true
      - DISABLE_SECURITY_PLUGIN=true
      # Workaround on OSX for https://bugs.openjdk.org/browse/JDK-8345296
      - _JAVA_OPTIONS
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    networks:
      - meteroid_net
    ports:
      - "9200:9200"
    healthcheck:
      test: curl -s http://localhost:9200/_cluster/health | grep -E '"status":"(green|yellow)"'
      start_period: 10s
      interval: 5s
      timeout: 10s
      retries: 10
    logging: *logging
